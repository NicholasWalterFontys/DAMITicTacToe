\section{Result}
As a final step, we had to answer the three questions we started this project with:

Can we teach an \ac{AI} to play Tic Tac Toe? \\
The short answer is yes, we were able to implement an \ac{AI} that learns to play the game only based on experience without any additional input. What this means is that invalid moves are very rare occurences which could probably be resolved with more training iterations.
As for the longer answer, we have to say that the \ac{AI} was sadly not able to develop any winning strategies or even to recognise an easy opportunity to win: Even when intentionally leaving plays open, it often did not use these and opted instead to block an enemy move.
We assume that, given more time, we would be able to restructure the neural net or change the rewards/ punishments to reach a better result.
\\

How many practice games does the \ac{AI} need to play to become proficient at playing the game? \\
Our results show that even after as few iterations as 10,000 the \ac{AI} is able to make mostly valid moves, however as said above, it would be stretching the truth to say that we ever reached a state where the \ac{AI} actually became "proficient" at playing.
\\

Can the \ac{AI} beat a human player? \\
Except for very few instances, our \ac{AI} was unable to beat a player consistently or even be a valid opponent (see section \ref{sec:verify}). As mentioned above, this may be resolvable by using a differently structured neural net and/ or more carefully selected rewards.