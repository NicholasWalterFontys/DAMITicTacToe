\section{Result}
As a final step, we had to answer the three questions we started this project with:

Can we teach an AI to play Tic Tac Toe?
The short answer is yes, we were able to implement an AI that learns to play the game only based on experience without any additional input. What this means is that invalid moves are very rare occurences which could probably be resolved with more training iterations.
As for the longer answer, we have to say that the AI was sadly not able to develop any winning strategies or even to recognise an easy opportunity to win: Even when intentionally leaving plays open, it often did not use these and opted instead to block an enemy move.
We assume that, given more time, we would be able to restructure the neural net or change the rewards/ punishments to reach a better result.
\\

How many practice games does the AI need to play to become proficient at playing the game?
Our results show that even after as few iterations as 10,000 the AI is able to make mostly valid moves, however as said above, it would be stretching the truth to say that we ever reached a state where the AI actually became "proficient" at playing.
\\

Can the AI beat a human player?
Except for very few instances, our AI was unable to beat a player consistently or even be a valid opponent (see chapter 5). As mentioned above, this may be resolvable by using a differently structured neural net and/ or more carefully selected rewards.