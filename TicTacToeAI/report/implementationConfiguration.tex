\section{Configuration of Implementation Platform}

Once the basic framework for our implementation was decided upon, the next step was to configure it to fit our needs. This meant defining the structure of the neural net we wanted to use as well as the rewards/ punishments the algorithm would receive for each possible action.

We initially based our decisions regarding the neural net's structure on other examples of game AIs using a similar approach, such as the learning RC-car project as well as the "Keras plays Catch" example ((////link to references? how?)). However while we were able to run our code with these structures and some slight modifications, neither of them yielded the results we wanted to see: The AI did not seem to actually learn the game.

Afterwards we decided to start from scratch and implement the structure from the ground up: A single layer of densely connected neurons was the result of this process: It takes 9 input arguments (the values of each of the segments of the Tic Tac Toe field, e.g. "empty", "own mark" or "enemy mark" expressed as integers) and produces 9 outputs (a confidence value between 0 and 1 as a float depicting the probability that the corresponding action would be rewarded highly). By selecting the action associated with the highest predicted probability of success, the AI then "decides" upon an action to take.

The next step was to define the rewards and punishments for each of the actions that the AI could possibly carry out: We started this process by defining what possible game moves were. Later, we decided how big of a reward each action should yield:

\begin{enumerate}
	\item Placing a mark on any empty square: 100
	\item Placing a mark to block the enemy from placing two marks in a row: 200
	\item Placing a mark to have two marks next to each other: 300
	\item Placing a mark to block an enemy win: 400
	\item Winning the game: 500
	\item Losing the game: -500
	\item Game ends in a draw: 0
	\item Making an invalid move: -2000
\end{enumerate}

Implementing the overall game framework therefore also involved checking the AI's actions to see whether any of these moves were done.